{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каталог с данными для обучения\n",
    "train_dir = './data/training'\n",
    "\n",
    "# Каталог с данными для проверки\n",
    "val_dir = './data/test'\n",
    "\n",
    "# Каталог с данными для тестирования\n",
    "test_dir = 'test'\n",
    "\n",
    "# Размеры изображения\n",
    "img_width, img_height = 64, 64 #150, 150\n",
    "\n",
    "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
    "# backend Tensorflow, channels_last\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Количество эпох\n",
    "epochs = 30\n",
    "\n",
    "# Размер мини-выборки\n",
    "batch_size = 16\n",
    "\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 13220\n",
    "\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 505\n",
    "\n",
    "# Количество изображений для тестирования\n",
    "#\\nb_test_samples = 3750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13220 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# создаём модель\n",
    "model = Sequential()\n",
    "\n",
    "# первый свёрточный слой\n",
    "#32 - карты признаков, размер ядра свёртки 3х3,\n",
    "#вход 3 канальный цвет в-32, ш-32\n",
    "model.add(Convolution2D(32,(3,3), border_mode='same',\n",
    "                       input_shape=input_shape, activation='relu'))\n",
    "\n",
    "# второй свёрточный слой \n",
    "#32 - карты признаков, размер ядра свёртки 3х3,\n",
    "model.add(Convolution2D(32, (3,3), activation='relu'))\n",
    "\n",
    "# слой подвыборки\n",
    "# из квадрата 2х2 выбирается максимальное значение\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# слой регуляризации \n",
    "# отключает некоторые нейроны с вероятностью 25% чтобы предотвратить переобучение \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#---------------------------------------------\n",
    "# третий свёрточный слой \n",
    "# уже 64 карты признаков \n",
    "model.add(Convolution2D(64, (3,3), border_mode='same',\n",
    "                       activation='relu'))\n",
    "\n",
    "# четвёртый свёрточный слой \n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "\n",
    "# второй слой подвыборки \n",
    "# максимальное значение из квадрата 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# слой регуляции\n",
    "#регуляризация откл нейронов\n",
    "model.add(Dropout(0.25))\n",
    "#--------------------------------------------\n",
    "# Классификатор\n",
    "# преобразование из двумерного вида в плоский \n",
    "model.add(Flatten())\n",
    "# полносвязный слой\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#слой регуляризации\n",
    "model.add(Dropout(0.5))\n",
    "#выходкой слой \n",
    "model.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем сеть \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 [==============================] - 292s 354ms/step - loss: 1.3277 - acc: 0.4763 - val_loss: 2.0040 - val_acc: 0.4510\n",
      "Epoch 2/30\n",
      "826/826 [==============================] - 285s 345ms/step - loss: 0.8201 - acc: 0.7157 - val_loss: 1.0539 - val_acc: 0.6157\n",
      "Epoch 3/30\n",
      "826/826 [==============================] - 285s 346ms/step - loss: 0.4716 - acc: 0.8441 - val_loss: 0.8606 - val_acc: 0.6471\n",
      "Epoch 4/30\n",
      "826/826 [==============================] - 287s 348ms/step - loss: 0.3561 - acc: 0.8851 - val_loss: 0.7562 - val_acc: 0.7412\n",
      "Epoch 5/30\n",
      "826/826 [==============================] - 281s 340ms/step - loss: 0.2822 - acc: 0.9044 - val_loss: 0.8249 - val_acc: 0.7647\n",
      "Epoch 6/30\n",
      "826/826 [==============================] - 278s 336ms/step - loss: 0.2331 - acc: 0.9206 - val_loss: 0.5400 - val_acc: 0.8000\n",
      "Epoch 7/30\n",
      "826/826 [==============================] - 280s 339ms/step - loss: 0.2041 - acc: 0.9310 - val_loss: 0.4970 - val_acc: 0.8392\n",
      "Epoch 8/30\n",
      "826/826 [==============================] - 281s 340ms/step - loss: 0.1756 - acc: 0.9443 - val_loss: 0.5751 - val_acc: 0.7843\n",
      "Epoch 9/30\n",
      "826/826 [==============================] - 282s 342ms/step - loss: 0.1662 - acc: 0.9447 - val_loss: 0.4023 - val_acc: 0.8588\n",
      "Epoch 10/30\n",
      "826/826 [==============================] - 281s 340ms/step - loss: 0.1440 - acc: 0.9527 - val_loss: 0.4573 - val_acc: 0.8627\n",
      "Epoch 11/30\n",
      "826/826 [==============================] - 285s 345ms/step - loss: 0.1268 - acc: 0.9604 - val_loss: 0.2767 - val_acc: 0.9176\n",
      "Epoch 12/30\n",
      "826/826 [==============================] - 298s 361ms/step - loss: 0.1147 - acc: 0.9663 - val_loss: 0.3026 - val_acc: 0.8784\n",
      "Epoch 13/30\n",
      "826/826 [==============================] - 294s 356ms/step - loss: 0.1129 - acc: 0.9642 - val_loss: 0.3186 - val_acc: 0.8980\n",
      "Epoch 14/30\n",
      "826/826 [==============================] - 294s 356ms/step - loss: 0.1000 - acc: 0.9695 - val_loss: 0.2944 - val_acc: 0.9098\n",
      "Epoch 15/30\n",
      "826/826 [==============================] - 287s 347ms/step - loss: 0.0858 - acc: 0.9738 - val_loss: 0.2844 - val_acc: 0.9020\n",
      "Epoch 16/30\n",
      "826/826 [==============================] - 295s 357ms/step - loss: 0.0859 - acc: 0.9728 - val_loss: 0.3145 - val_acc: 0.8980\n",
      "Epoch 17/30\n",
      "826/826 [==============================] - 295s 357ms/step - loss: 0.0780 - acc: 0.9757 - val_loss: 0.2894 - val_acc: 0.9176\n",
      "Epoch 18/30\n",
      "826/826 [==============================] - 297s 360ms/step - loss: 0.0716 - acc: 0.9771 - val_loss: 0.2805 - val_acc: 0.9255\n",
      "Epoch 19/30\n",
      "826/826 [==============================] - 300s 363ms/step - loss: 0.0596 - acc: 0.9803 - val_loss: 0.4903 - val_acc: 0.8667\n",
      "Epoch 20/30\n",
      "826/826 [==============================] - 299s 362ms/step - loss: 0.0625 - acc: 0.9806 - val_loss: 0.3201 - val_acc: 0.9098\n",
      "Epoch 21/30\n",
      "826/826 [==============================] - 294s 356ms/step - loss: 0.0611 - acc: 0.9826 - val_loss: 0.2585 - val_acc: 0.9294\n",
      "Epoch 22/30\n",
      "826/826 [==============================] - 299s 362ms/step - loss: 0.0580 - acc: 0.9821 - val_loss: 0.2172 - val_acc: 0.9255\n",
      "Epoch 23/30\n",
      "826/826 [==============================] - 296s 358ms/step - loss: 0.0604 - acc: 0.9810 - val_loss: 0.1822 - val_acc: 0.9490\n",
      "Epoch 24/30\n",
      "826/826 [==============================] - 295s 357ms/step - loss: 0.0519 - acc: 0.9845 - val_loss: 0.3278 - val_acc: 0.9098\n",
      "Epoch 25/30\n",
      "826/826 [==============================] - 298s 360ms/step - loss: 0.0527 - acc: 0.9837 - val_loss: 0.2947 - val_acc: 0.9137\n",
      "Epoch 26/30\n",
      "826/826 [==============================] - 300s 363ms/step - loss: 0.0411 - acc: 0.9865 - val_loss: 0.1826 - val_acc: 0.9451\n",
      "Epoch 27/30\n",
      "826/826 [==============================] - 298s 361ms/step - loss: 0.0548 - acc: 0.9817 - val_loss: 0.3085 - val_acc: 0.9255\n",
      "Epoch 28/30\n",
      "826/826 [==============================] - 294s 356ms/step - loss: 0.0487 - acc: 0.9852 - val_loss: 0.2308 - val_acc: 0.9490\n",
      "Epoch 29/30\n",
      "826/826 [==============================] - 295s 357ms/step - loss: 0.0438 - acc: 0.9862 - val_loss: 0.1484 - val_acc: 0.9529\n",
      "Epoch 30/30\n",
      "826/826 [==============================] - 299s 362ms/step - loss: 0.0533 - acc: 0.9839 - val_loss: 0.2092 - val_acc: 0.9451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xbda9d0cd68>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc: 0.9839, val_acc: 0.9451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('road_sign_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем описание модели в формате json\n",
    "model_json = model.to_json()\n",
    "\n",
    "#записываем модель в файл\n",
    "json_file = open('road_sign_model.json', 'w')\n",
    "json_file.write(model_json)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('road_sign_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02577223068471021, 0.9921331316187595]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(train_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
